{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588d0c69bbd6a764",
   "metadata": {},
   "source": [
    "# Neural Network by implementing it yourselF\n",
    "\n",
    "In this assignment, create your **own neural network** using only the Core Python 3.x and *NumPy* library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9eb277d07b358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name = 'Juha-Matti Hellsten'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b37bc9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Coordinate pairs have been defined in the assignment, and they are used to draw points of two colors (red and blue).\n",
    "The ultimate goal is to create a neural network that knows how to place a point in the red or blue areas of the coordinate system.\n",
    "\n",
    "When a new point is drawn on the graph and the coordinates of the point are fed to the neural network,\n",
    "the neural network predicts the color of the point and the probability that it is that color.\n",
    "\n",
    "The meaning of the assignment: to better understand the functioning of the neural network algorithm.\n",
    "\n",
    "The steps of the assignment are:\n",
    "\n",
    "1. Create training data with coordinate points with colors.\n",
    "2. Create a neural network class with the structure:\n",
    "* Input layer with two neurons (x, y) i.e., the coordinate pairs for the (x, y) point.\n",
    "* One hidden layer with six (6) neurons and sigmoid as activation function.\n",
    "* Output layer with one neuron and sigmoid as activation function.\n",
    "* The result of the output layer is therefore a float between [0, 1].\n",
    "3. Create functions to calculate the neural network's prediction for the input data (*forwardpropagation*) and\n",
    "   update the connection weight values with the error (*backpropagation*).\n",
    "4. Feed the training data 1000 times through the neural network.\n",
    "* In each epoch round, feed the training data row by row through the neural network and update the weight values.\n",
    "* During the round, save the errors for each input, and add the average of the round's loss to the list. Draw a graph of how the loss changes during training epochs.\n",
    "5. Predict with a neural network (float value) what color the point will be: `[0.5, 8.7]`. How accurate do you think this prediction is?\n",
    "6. Predict with a neural network (float value) what color the point is: `[15, -15]`. How accurate do you think this prediction is?\n",
    "7. Find out how the change in the `learning_rate` argument of the `backpropagation()` method affects the (try values from `0.01` to `0.001`) result?\n",
    "8. Find out how changing the `n_samples` property of `make_blobs()` affects the result?\n",
    "9. Find out how changing the `cluster_std` property of `make_blobs()` affects the result?\n",
    "\n",
    "Tips:\n",
    "* Draw the structure of this neural network with a drawing program or on paper, where you can see the number of connections in each layer.\n",
    "* Use the existing solution, and add to it only the necessary calculations for each layer of neural network.\n",
    "\n",
    "Once the error (loss) function is defined, the _gradient descent_ method is used to minimize it.\n",
    "In it, the gradient of the error function is calculated in relation to the weighting coefficients, and\n",
    "it moves step by step to the opposite direction with respect to the gradient until an optimum is found.\n",
    "\n",
    "### What do you need to implement in this assignment?\n",
    "\n",
    "* `class NeuralNetwork` - ready-to-use class, i.e., no changes needed\n",
    "* `train_neural_network()` - ready to use, trains the neural network and saves the loss after each round\n",
    "* `create_dots_and_labels()` - requires also own implementation\n",
    " * plot the losses of the neural network\n",
    "*  calculate the neural network prediction for the input `[x, y]` in the given variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28422c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:32.545655Z",
     "start_time": "2024-12-12T14:33:31.363819Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18b8b1f23f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This assignment uses the make_blobs() function, which can be used to draw the test dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "dots, labels = make_blobs(n_samples=50, centers=2, cluster_std=8, center_box=(-20, 20), random_state=151)\n",
    "colors = ['red' if label == 0 else 'blue' for label in labels]\n",
    "plt.scatter(dots[:, 0], dots[:, 1], color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec4d00b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:32.593527Z",
     "start_time": "2024-12-12T14:33:32.559619Z"
    }
   },
   "outputs": [],
   "source": [
    "# `NeuralNetwork` is a ready-to-use class as is.\n",
    "import numpy as np\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.weights1 = np.random.rand(2, 6)\n",
    "        self.weights2 = np.random.rand(6, 1)\n",
    "\n",
    "    def __init__(self, input_neurons, hidden_neurons):\n",
    "        self.weights1 = np.random.rand(input_neurons, hidden_neurons)\n",
    "        self.weights2 = np.random.rand(hidden_neurons, 1)\n",
    "\n",
    "    # Loss function\n",
    "    def loss_function(self, true, prediction):\n",
    "        return 0.5 * (true - prediction) ** 2\n",
    "\n",
    "    # Derivative of the loss function\n",
    "    def loss_function_derivative(self, true, prediction):\n",
    "        return true - prediction\n",
    "\n",
    "    # Sigmoid function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Derivative of the sigmoid\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # Traversal of the neural network\n",
    "    def forwardpropagation(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.layer1 = self.sigmoid(np.dot(self.X, self.weights1))\n",
    "        self.output = self.sigmoid(np.dot(self.layer1, self.weights2))\n",
    "\n",
    "        # the loss is calculated, i.e., the distance of the neural network's predictions from the correct values\n",
    "        self.loss = self.loss_function(self.y, self.output)\n",
    "\n",
    "    # Update weight values using the backpropagation method\n",
    "    def backpropagation(self, learning_rate):\n",
    "        output_error = self.loss_function_derivative(self.y, self.output)\n",
    "        output_delta = output_error * self.sigmoid_derivative(self.output)\n",
    "        weights2_adjustment = np.dot(self.layer1.T, output_delta)\n",
    "\n",
    "        layer1_error = np.dot(output_delta, self.weights2.T)\n",
    "        layer1_delta = layer1_error * self.sigmoid_derivative(self.layer1)\n",
    "        weights1_adjustment = np.dot(self.X.T, layer1_delta)\n",
    "\n",
    "        self.weights1 += learning_rate * weights1_adjustment\n",
    "        self.weights2 += learning_rate * weights2_adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e4f9e",
   "metadata": {},
   "source": [
    "\n",
    "Implement function `create_dots_and_labels()`, that creates the dots and labels and set the RGB color for the dot based on the labels.\n",
    "\n",
    "You must do the following:\n",
    "* Create a color table where the color is `[label: 0: \"red\" or 1: \"blue\"]`\n",
    "* Find out how `make_blobs()` works.\n",
    "\n",
    "`train_neural_network()`: Trains the neural network and saves the loss after each epoch round\n",
    "\n",
    "see **TODO** items that require you to write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5f194c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:32.860811Z",
     "start_time": "2024-12-12T14:33:32.833885Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: create_dots_and_labels() function should return list with `[dots, labels, colors]`\n",
    "def create_dots_and_labels():\n",
    "    # TODO: Find out how increasing the cluster_std property of make_blobs() affects the result?\n",
    "    dots, labels = make_blobs(n_samples=50, centers=2, cluster_std=8, center_box=(-20, 20), random_state=151)\n",
    "    colors = ['red' if label == 0 else 'blue'for label in labels]\n",
    "    # TODO: Create a color table where the color is [\"red\" or \"blue\"]\n",
    "    # TODO: Create the colors list based on the values of the labels list\n",
    "\n",
    "    return [dots, labels, colors]\n",
    "\n",
    "\n",
    "# Train the neural network and save the loss after each epoch round (this has been already implemented)\n",
    "def train_neural_network(ntwrk, train_X, train_y):\n",
    "    losses_arr = [] \n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "      \n",
    "        for X, y in zip(train_X, train_y):\n",
    "            ntwrk.forwardpropagation(np.array([X]), np.array([y]))\n",
    "            # TODO: Find out how does the learning_rate change affect the (from 0.01 to 0.001) result?\n",
    "            ntwrk.backpropagation(learning_rate=0.01)\n",
    "            batch_losses.append(ntwrk.loss[0])\n",
    "        losses_arr.append(np.average(batch_losses))\n",
    "    return losses_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccd3b6",
   "metadata": {},
   "source": [
    "* Defining the training data and creating the neural network\n",
    "* create_dots_and_labels\n",
    "* Plot the points with *scatter plot*\n",
    "* You should train the neural network and save the loss of the neural network after each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a8b59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:32.906690Z",
     "start_time": "2024-12-12T14:33:32.897713Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create and train a neural network\n",
    "# ... NeuralNetwork(input_layer_neurons, hidden_layer_neurons)\n",
    "# ... train_neural_network(...)\n",
    "\n",
    "# TODO: Create and train the neural network and save the loss of the neural network after each round\n",
    "\n",
    "network = NeuralNetwork(2, 6)  # 2 input neuronia, 6 hidden neuronia\n",
    "dots, labels, colors = create_dots_and_labels()\n",
    "\n",
    "losses = train_neural_network(network, dots, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb3d55",
   "metadata": {},
   "source": [
    "Let's plot the losses of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5dedd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:32.954561Z",
     "start_time": "2024-12-12T14:33:32.943590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Plot the losses of the neural network\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136a6be",
   "metadata": {},
   "source": [
    "### Let's calculate the following predictions\n",
    "* Calculate the neural network prediction for the input `[0.5, 8.7]` in the `output1` variable.\n",
    "* Calculate the neural network prediction for the input `[15, -15]` in the `output2` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93424e34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:33.003431Z",
     "start_time": "2024-12-12T14:33:32.991464Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate two predictions for given (x,y) points\n",
    "\n",
    "test_X_nn = np.array([0.5, 8.7])\n",
    "layer1_output = network.sigmoid(np.dot(test_X_nn, network.weights1))\n",
    "output1 = network.sigmoid(np.dot(layer1_output, network.weights2))\n",
    "\n",
    "# TODO: Calculate the prediction for the first input\n",
    "test_X_nn = np.array([0.5, 8.7])\n",
    "\n",
    "layer1_output = network.sigmoid(np.dot(test_X_nn, network.weights1))\n",
    "output1 = network.sigmoid(np.dot(layer1_output, network.weights2))\n",
    "\n",
    "\n",
    "# TODO: Calculate the prediction for the second input\n",
    "test_X_nn2 = np.array([15, -15])\n",
    "layer1_output2 = network.sigmoid(np.dot(test_X_nn2, network.weights1))\n",
    "output2 = network.sigmoid(np.dot(layer1_output2, network.weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6636dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:33.050306Z",
     "start_time": "2024-12-12T14:33:33.039334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95304401]\n",
      "[0.04023055]\n"
     ]
    }
   ],
   "source": [
    "# Answers to the assignment. Note! Do not edit this cell, just run it after you complete the assignment.\n",
    "print(output1)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7785b",
   "metadata": {},
   "source": [
    "## Topic: Simple neural network with Keras Sequential API (max. 3 p)\n",
    "\n",
    "Train a simple neural network with the **Keras** interface using *Titanic dataset*.\n",
    "\n",
    "You can get the dataset from the URL: `https://student.labranet.jamk.fi/~varpe/datananalk2019/kerta10/titanic.csv`\n",
    "\n",
    "Steps that must be found in the assignment:\n",
    "1. Choose only the most important features from the Titanic data\n",
    "2. Create a neural network (use `tf.keras.Sequential()` method)\n",
    "3. Define loss function and optimizer (use `model.compile()` method)\n",
    "4. Train the neural network (use `model.fit()` method)\n",
    "5. Compare the predictions given by the neural network with the test data (use the `model.evaluate()` method)\n",
    "6. Print the results of the epochs to the console.\n",
    "7. Change the structure of the neural network and try to document the neural network with which you got the best results.\n",
    "* 500 - 1000 learning rounds (epochs) are certainly enough for this neural network.\n",
    "\n",
    "Example output:\n",
    "```\n",
    "23/23 [==============================] - 0s 687us/step - loss: 2.2182 - accuracy: 0.6236\n",
    "Epoch 2/1000\n",
    "23/23 [==============================] - 0s 702us/step - loss: 1.4468 - accuracy: 0.6238\n",
    "```\n",
    "\n",
    "Note! It's worth trying several neural network structures and comparing the learning results a little.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641abfb",
   "metadata": {},
   "source": [
    "### Data preprocessing + Keras - Titanic dataset\n",
    "\n",
    "A version that aims to retrieve the most important features that are most correlated with the `survived` field (class variable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b40983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:33.336543Z",
     "start_time": "2024-12-12T14:33:33.092199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Implementation of the assignment\n",
    "# TODO: Implement Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('https://student.labranet.jamk.fi/~varpe/datananalk2019/kerta10/titanic.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919339d805c631a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "If you get *\"SSL certificate expired error\"*, the above code will help.\n",
    "\n",
    "Another alternative is to just copy the CSV file to your own local repository to do the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbaf71a3df8eace4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:33.399373Z",
     "start_time": "2024-12-12T14:33:33.387408Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# df = pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201fe358",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Splitting the Data\n",
    "* Extract the class variable from the data.\n",
    "* Divide the data into training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aefbc9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:33.462203Z",
     "start_time": "2024-12-12T14:33:33.450236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (712, 6)\n",
      "Testing set shape: (179, 6)\n"
     ]
    }
   ],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "X = df[features]  \n",
    "y = df['Survived']\n",
    "\n",
    "X.loc[:, 'Age'] = X['Age'].fillna(X['Age'].median())\n",
    "X.loc[:, 'Sex'] = (X['Sex'] == 'female').astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa082dbf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Implementation of the assignment using the Keras library\n",
    "\n",
    "Create a neural network with `Dense` layers one after the other (`Sequential`). Specify these two parameters at least:\n",
    "* `units` – dimensionality of the output space.\n",
    "* `activation` – Activation function to use.\n",
    "\n",
    "Creating a neural network based on `Sequential` class.\n",
    "\n",
    "      model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(neurons, activation='relu'), ...\n",
    "          # Define Layers in between (one or more hidden layers)\n",
    "          # In the output layer there is only one neuron (i.e. Survived, the output value is between 0-1)\n",
    "\n",
    "Note! It is worth trying several neural network structures and comparing the learning results of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1113980a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:40.041599Z",
     "start_time": "2024-12-12T14:33:33.498110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\juha-mattihellstén\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\juha-mattihellstén\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Implementation of assignment\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# TODO: Create a neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(6,)),  # Tämä määrittää syötekerroksen muodon\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a5b03",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Next steps in the assignment are:\n",
    "\n",
    "* Compile the model (`model.compile()`)\n",
    "* Train the neural network with *n epoch* rounds (`model.fit()`)\n",
    "* Compare the obtained learning results with the test data (`model.evaluate()`)\n",
    "* define loss function: `loss='binary_crossentropy'`\n",
    "\n",
    "Note! `verbose=1` is a good option in the fit()/evaluate() functions, which allows you to see how the teaching progresses by epoch cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a483b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:40.089472Z",
     "start_time": "2024-12-12T14:33:40.077503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4930 - loss: 0.7000 - val_accuracy: 0.6224 - val_loss: 0.6945\n",
      "Epoch 2/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5680 - loss: 0.6921 - val_accuracy: 0.6783 - val_loss: 0.6868\n",
      "Epoch 3/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6189 - loss: 0.6864 - val_accuracy: 0.6993 - val_loss: 0.6801\n",
      "Epoch 4/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6619 - loss: 0.6651 - val_accuracy: 0.6783 - val_loss: 0.6745\n",
      "Epoch 5/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6767 - loss: 0.6646 - val_accuracy: 0.6713 - val_loss: 0.6687\n",
      "Epoch 6/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6986 - loss: 0.6610 - val_accuracy: 0.6713 - val_loss: 0.6626\n",
      "Epoch 7/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7252 - loss: 0.6417 - val_accuracy: 0.6783 - val_loss: 0.6563\n",
      "Epoch 8/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7284 - loss: 0.6333 - val_accuracy: 0.6853 - val_loss: 0.6485\n",
      "Epoch 9/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7564 - loss: 0.6311 - val_accuracy: 0.7063 - val_loss: 0.6395\n",
      "Epoch 10/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7544 - loss: 0.6271 - val_accuracy: 0.7203 - val_loss: 0.6299\n",
      "Epoch 11/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7574 - loss: 0.6182 - val_accuracy: 0.7343 - val_loss: 0.6196\n",
      "Epoch 12/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.5978 - val_accuracy: 0.7483 - val_loss: 0.6075\n",
      "Epoch 13/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7582 - loss: 0.6004 - val_accuracy: 0.7692 - val_loss: 0.5955\n",
      "Epoch 14/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7415 - loss: 0.5993 - val_accuracy: 0.7832 - val_loss: 0.5825\n",
      "Epoch 15/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7810 - loss: 0.5748 - val_accuracy: 0.7902 - val_loss: 0.5696\n",
      "Epoch 16/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7793 - loss: 0.5639 - val_accuracy: 0.8042 - val_loss: 0.5550\n",
      "Epoch 17/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7565 - loss: 0.5525 - val_accuracy: 0.8182 - val_loss: 0.5415\n",
      "Epoch 18/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7494 - loss: 0.5484 - val_accuracy: 0.8252 - val_loss: 0.5278\n",
      "Epoch 19/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7634 - loss: 0.5414 - val_accuracy: 0.8182 - val_loss: 0.5141\n",
      "Epoch 20/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7875 - loss: 0.5217 - val_accuracy: 0.8182 - val_loss: 0.5033\n",
      "Epoch 21/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7749 - loss: 0.5144 - val_accuracy: 0.8182 - val_loss: 0.4931\n",
      "Epoch 22/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7988 - loss: 0.4820 - val_accuracy: 0.8252 - val_loss: 0.4839\n",
      "Epoch 23/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7912 - loss: 0.4995 - val_accuracy: 0.8252 - val_loss: 0.4766\n",
      "Epoch 24/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7982 - loss: 0.4921 - val_accuracy: 0.8252 - val_loss: 0.4694\n",
      "Epoch 25/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7954 - loss: 0.4796 - val_accuracy: 0.8252 - val_loss: 0.4637\n",
      "Epoch 26/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8018 - loss: 0.4697 - val_accuracy: 0.8252 - val_loss: 0.4594\n",
      "Epoch 27/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7982 - loss: 0.4803 - val_accuracy: 0.8252 - val_loss: 0.4560\n",
      "Epoch 28/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8054 - loss: 0.4666 - val_accuracy: 0.8252 - val_loss: 0.4537\n",
      "Epoch 29/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8138 - loss: 0.4600 - val_accuracy: 0.8252 - val_loss: 0.4520\n",
      "Epoch 30/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8019 - loss: 0.4559 - val_accuracy: 0.8252 - val_loss: 0.4487\n",
      "Epoch 31/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7728 - loss: 0.4974 - val_accuracy: 0.8252 - val_loss: 0.4471\n",
      "Epoch 32/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8170 - loss: 0.4530 - val_accuracy: 0.8252 - val_loss: 0.4453\n",
      "Epoch 33/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8340 - loss: 0.4307 - val_accuracy: 0.8252 - val_loss: 0.4435\n",
      "Epoch 34/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.4604 - val_accuracy: 0.8112 - val_loss: 0.4435\n",
      "Epoch 35/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7906 - loss: 0.4819 - val_accuracy: 0.8182 - val_loss: 0.4419\n",
      "Epoch 36/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8059 - loss: 0.4582 - val_accuracy: 0.8182 - val_loss: 0.4407\n",
      "Epoch 37/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7798 - loss: 0.4774 - val_accuracy: 0.8112 - val_loss: 0.4406\n",
      "Epoch 38/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7966 - loss: 0.4539 - val_accuracy: 0.8112 - val_loss: 0.4403\n",
      "Epoch 39/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.4663 - val_accuracy: 0.8112 - val_loss: 0.4393\n",
      "Epoch 40/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8174 - loss: 0.4319 - val_accuracy: 0.8112 - val_loss: 0.4374\n",
      "Epoch 41/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7987 - loss: 0.4410 - val_accuracy: 0.8112 - val_loss: 0.4369\n",
      "Epoch 42/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7963 - loss: 0.4795 - val_accuracy: 0.8112 - val_loss: 0.4377\n",
      "Epoch 43/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 0.4723 - val_accuracy: 0.8112 - val_loss: 0.4382\n",
      "Epoch 44/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7993 - loss: 0.4593 - val_accuracy: 0.8112 - val_loss: 0.4369\n",
      "Epoch 45/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8155 - loss: 0.4493 - val_accuracy: 0.8112 - val_loss: 0.4362\n",
      "Epoch 46/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8002 - loss: 0.4647 - val_accuracy: 0.8182 - val_loss: 0.4349\n",
      "Epoch 47/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7975 - loss: 0.4495 - val_accuracy: 0.8182 - val_loss: 0.4359\n",
      "Epoch 48/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7866 - loss: 0.4785 - val_accuracy: 0.8182 - val_loss: 0.4348\n",
      "Epoch 49/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8128 - loss: 0.4259 - val_accuracy: 0.8182 - val_loss: 0.4343\n",
      "Epoch 50/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4207 - val_accuracy: 0.8182 - val_loss: 0.4329\n",
      "Epoch 51/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7885 - loss: 0.4703 - val_accuracy: 0.8182 - val_loss: 0.4345\n",
      "Epoch 52/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8095 - loss: 0.4316 - val_accuracy: 0.8182 - val_loss: 0.4330\n",
      "Epoch 53/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7976 - loss: 0.4463 - val_accuracy: 0.8182 - val_loss: 0.4333\n",
      "Epoch 54/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.4660 - val_accuracy: 0.8182 - val_loss: 0.4329\n",
      "Epoch 55/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7925 - loss: 0.4604 - val_accuracy: 0.8182 - val_loss: 0.4323\n",
      "Epoch 56/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7948 - loss: 0.4526 - val_accuracy: 0.8182 - val_loss: 0.4321\n",
      "Epoch 57/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8063 - loss: 0.4629 - val_accuracy: 0.8182 - val_loss: 0.4312\n",
      "Epoch 58/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7846 - loss: 0.4699 - val_accuracy: 0.8182 - val_loss: 0.4325\n",
      "Epoch 59/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.4840 - val_accuracy: 0.8182 - val_loss: 0.4316\n",
      "Epoch 60/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8121 - loss: 0.4430 - val_accuracy: 0.8252 - val_loss: 0.4307\n",
      "Epoch 61/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7614 - loss: 0.5068 - val_accuracy: 0.8182 - val_loss: 0.4314\n",
      "Epoch 62/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8128 - loss: 0.4278 - val_accuracy: 0.8252 - val_loss: 0.4322\n",
      "Epoch 63/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7940 - loss: 0.4451 - val_accuracy: 0.8252 - val_loss: 0.4301\n",
      "Epoch 64/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7864 - loss: 0.4481 - val_accuracy: 0.8252 - val_loss: 0.4293\n",
      "Epoch 65/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8021 - loss: 0.4424 - val_accuracy: 0.8252 - val_loss: 0.4293\n",
      "Epoch 66/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7945 - loss: 0.4296 - val_accuracy: 0.8252 - val_loss: 0.4288\n",
      "Epoch 67/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7873 - loss: 0.4570 - val_accuracy: 0.8252 - val_loss: 0.4287\n",
      "Epoch 68/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7885 - loss: 0.4615 - val_accuracy: 0.8322 - val_loss: 0.4289\n",
      "Epoch 69/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8036 - loss: 0.4461 - val_accuracy: 0.8322 - val_loss: 0.4289\n",
      "Epoch 70/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8297 - loss: 0.4089 - val_accuracy: 0.8322 - val_loss: 0.4280\n",
      "Epoch 71/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.4424 - val_accuracy: 0.8322 - val_loss: 0.4276\n",
      "Epoch 72/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7877 - loss: 0.4617 - val_accuracy: 0.8322 - val_loss: 0.4290\n",
      "Epoch 73/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8153 - loss: 0.4276 - val_accuracy: 0.8392 - val_loss: 0.4270\n",
      "Epoch 74/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7926 - loss: 0.4537 - val_accuracy: 0.8392 - val_loss: 0.4274\n",
      "Epoch 75/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8004 - loss: 0.4418 - val_accuracy: 0.8392 - val_loss: 0.4270\n",
      "Epoch 76/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8099 - loss: 0.4027 - val_accuracy: 0.8392 - val_loss: 0.4259\n",
      "Epoch 77/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7889 - loss: 0.4544 - val_accuracy: 0.8392 - val_loss: 0.4273\n",
      "Epoch 78/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8058 - loss: 0.4288 - val_accuracy: 0.8392 - val_loss: 0.4272\n",
      "Epoch 79/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8084 - loss: 0.4324 - val_accuracy: 0.8392 - val_loss: 0.4266\n",
      "Epoch 80/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8017 - loss: 0.4347 - val_accuracy: 0.8392 - val_loss: 0.4267\n",
      "Epoch 81/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7815 - loss: 0.4806 - val_accuracy: 0.8392 - val_loss: 0.4258\n",
      "Epoch 82/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8007 - loss: 0.4253 - val_accuracy: 0.8322 - val_loss: 0.4254\n",
      "Epoch 83/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8110 - loss: 0.4368 - val_accuracy: 0.8322 - val_loss: 0.4261\n",
      "Epoch 84/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7681 - loss: 0.4736 - val_accuracy: 0.8322 - val_loss: 0.4253\n",
      "Epoch 85/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.4062 - val_accuracy: 0.8392 - val_loss: 0.4245\n",
      "Epoch 86/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8263 - loss: 0.4195 - val_accuracy: 0.8322 - val_loss: 0.4261\n",
      "Epoch 87/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8148 - loss: 0.4275 - val_accuracy: 0.8392 - val_loss: 0.4251\n",
      "Epoch 88/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8027 - loss: 0.4402 - val_accuracy: 0.8392 - val_loss: 0.4249\n",
      "Epoch 89/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.3986 - val_accuracy: 0.8392 - val_loss: 0.4231\n",
      "Epoch 90/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7789 - loss: 0.4453 - val_accuracy: 0.8392 - val_loss: 0.4233\n",
      "Epoch 91/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8201 - loss: 0.4062 - val_accuracy: 0.8392 - val_loss: 0.4231\n",
      "Epoch 92/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8105 - loss: 0.4252 - val_accuracy: 0.8392 - val_loss: 0.4224\n",
      "Epoch 93/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.4382 - val_accuracy: 0.8322 - val_loss: 0.4232\n",
      "Epoch 94/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8258 - loss: 0.4080 - val_accuracy: 0.8252 - val_loss: 0.4230\n",
      "Epoch 95/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7961 - loss: 0.4488 - val_accuracy: 0.8392 - val_loss: 0.4222\n",
      "Epoch 96/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8264 - loss: 0.4172 - val_accuracy: 0.8322 - val_loss: 0.4222\n",
      "Epoch 97/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7896 - loss: 0.4464 - val_accuracy: 0.8252 - val_loss: 0.4223\n",
      "Epoch 98/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8003 - loss: 0.4824 - val_accuracy: 0.8392 - val_loss: 0.4211\n",
      "Epoch 99/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8117 - loss: 0.4285 - val_accuracy: 0.8322 - val_loss: 0.4204\n",
      "Epoch 100/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8032 - loss: 0.4286 - val_accuracy: 0.8322 - val_loss: 0.4196\n",
      "Epoch 101/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7992 - loss: 0.4431 - val_accuracy: 0.8252 - val_loss: 0.4204\n",
      "Epoch 102/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8138 - loss: 0.4257 - val_accuracy: 0.8252 - val_loss: 0.4201\n",
      "Epoch 103/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8103 - loss: 0.4419 - val_accuracy: 0.8112 - val_loss: 0.4214\n",
      "Epoch 104/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7992 - loss: 0.4501 - val_accuracy: 0.8252 - val_loss: 0.4201\n",
      "Epoch 105/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.4063 - val_accuracy: 0.8392 - val_loss: 0.4178\n",
      "Epoch 106/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8379 - loss: 0.3976 - val_accuracy: 0.8252 - val_loss: 0.4185\n",
      "Epoch 107/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8132 - loss: 0.4141 - val_accuracy: 0.8252 - val_loss: 0.4182\n",
      "Epoch 108/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8196 - loss: 0.4306 - val_accuracy: 0.8252 - val_loss: 0.4184\n",
      "Epoch 109/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7928 - loss: 0.4580 - val_accuracy: 0.8042 - val_loss: 0.4190\n",
      "Epoch 110/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8285 - loss: 0.4122 - val_accuracy: 0.8322 - val_loss: 0.4165\n",
      "Epoch 111/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.4257 - val_accuracy: 0.8252 - val_loss: 0.4189\n",
      "Epoch 112/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7949 - loss: 0.4571 - val_accuracy: 0.8252 - val_loss: 0.4179\n",
      "Epoch 113/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8287 - loss: 0.4300 - val_accuracy: 0.8252 - val_loss: 0.4160\n",
      "Epoch 114/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8161 - loss: 0.4302 - val_accuracy: 0.8252 - val_loss: 0.4164\n",
      "Epoch 115/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8059 - loss: 0.4366 - val_accuracy: 0.8392 - val_loss: 0.4145\n",
      "Epoch 116/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8057 - loss: 0.4340 - val_accuracy: 0.8392 - val_loss: 0.4144\n",
      "Epoch 117/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8225 - loss: 0.4178 - val_accuracy: 0.8322 - val_loss: 0.4158\n",
      "Epoch 118/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7946 - loss: 0.4324 - val_accuracy: 0.8322 - val_loss: 0.4152\n",
      "Epoch 119/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8249 - loss: 0.4326 - val_accuracy: 0.8392 - val_loss: 0.4148\n",
      "Epoch 120/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8284 - loss: 0.4017 - val_accuracy: 0.8392 - val_loss: 0.4144\n",
      "Epoch 121/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8182 - loss: 0.4186 - val_accuracy: 0.8322 - val_loss: 0.4144\n",
      "Epoch 122/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7839 - loss: 0.4781 - val_accuracy: 0.8462 - val_loss: 0.4136\n",
      "Epoch 123/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8219 - loss: 0.4246 - val_accuracy: 0.8462 - val_loss: 0.4129\n",
      "Epoch 124/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7914 - loss: 0.4309 - val_accuracy: 0.8462 - val_loss: 0.4124\n",
      "Epoch 125/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8279 - loss: 0.4151 - val_accuracy: 0.8462 - val_loss: 0.4129\n",
      "Epoch 126/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8086 - loss: 0.4328 - val_accuracy: 0.8462 - val_loss: 0.4130\n",
      "Epoch 127/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7929 - loss: 0.4663 - val_accuracy: 0.8462 - val_loss: 0.4126\n",
      "Epoch 128/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8128 - loss: 0.4069 - val_accuracy: 0.8462 - val_loss: 0.4121\n",
      "Epoch 129/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8161 - loss: 0.4399 - val_accuracy: 0.8462 - val_loss: 0.4126\n",
      "Epoch 130/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7874 - loss: 0.4602 - val_accuracy: 0.8462 - val_loss: 0.4113\n",
      "Epoch 131/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7917 - loss: 0.4517 - val_accuracy: 0.8462 - val_loss: 0.4110\n",
      "Epoch 132/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8024 - loss: 0.4450 - val_accuracy: 0.8462 - val_loss: 0.4130\n",
      "Epoch 133/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7925 - loss: 0.4525 - val_accuracy: 0.8462 - val_loss: 0.4112\n",
      "Epoch 134/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8097 - loss: 0.4313 - val_accuracy: 0.8462 - val_loss: 0.4110\n",
      "Epoch 135/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8190 - loss: 0.4189 - val_accuracy: 0.8462 - val_loss: 0.4111\n",
      "Epoch 136/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8262 - loss: 0.4182 - val_accuracy: 0.8462 - val_loss: 0.4114\n",
      "Epoch 137/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8139 - loss: 0.4253 - val_accuracy: 0.8462 - val_loss: 0.4109\n",
      "Epoch 138/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.4079 - val_accuracy: 0.8462 - val_loss: 0.4100\n",
      "Epoch 139/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7857 - loss: 0.4609 - val_accuracy: 0.8462 - val_loss: 0.4115\n",
      "Epoch 140/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4434 - val_accuracy: 0.8462 - val_loss: 0.4099\n",
      "Epoch 141/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8008 - loss: 0.4339 - val_accuracy: 0.8392 - val_loss: 0.4092\n",
      "Epoch 142/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8207 - loss: 0.4141 - val_accuracy: 0.8462 - val_loss: 0.4094\n",
      "Epoch 143/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8165 - loss: 0.4153 - val_accuracy: 0.8462 - val_loss: 0.4100\n",
      "Epoch 144/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8288 - loss: 0.4076 - val_accuracy: 0.8462 - val_loss: 0.4095\n",
      "Epoch 145/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8168 - loss: 0.4280 - val_accuracy: 0.8392 - val_loss: 0.4083\n",
      "Epoch 146/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8132 - loss: 0.4220 - val_accuracy: 0.8462 - val_loss: 0.4095\n",
      "Epoch 147/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8199 - loss: 0.4282 - val_accuracy: 0.8392 - val_loss: 0.4080\n",
      "Epoch 148/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8018 - loss: 0.4392 - val_accuracy: 0.8392 - val_loss: 0.4078\n",
      "Epoch 149/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8273 - loss: 0.4044 - val_accuracy: 0.8392 - val_loss: 0.4075\n",
      "Epoch 150/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8113 - loss: 0.4373 - val_accuracy: 0.8462 - val_loss: 0.4087\n",
      "Epoch 151/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8263 - loss: 0.4045 - val_accuracy: 0.8392 - val_loss: 0.4080\n",
      "Epoch 152/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8145 - loss: 0.4178 - val_accuracy: 0.8392 - val_loss: 0.4070\n",
      "Epoch 153/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8160 - loss: 0.4299 - val_accuracy: 0.8392 - val_loss: 0.4071\n",
      "Epoch 154/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8158 - loss: 0.4257 - val_accuracy: 0.8392 - val_loss: 0.4073\n",
      "Epoch 155/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8080 - loss: 0.4164 - val_accuracy: 0.8392 - val_loss: 0.4086\n",
      "Epoch 156/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8069 - loss: 0.4117 - val_accuracy: 0.8392 - val_loss: 0.4071\n",
      "Epoch 157/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8165 - loss: 0.4375 - val_accuracy: 0.8392 - val_loss: 0.4069\n",
      "Epoch 158/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7973 - loss: 0.4221 - val_accuracy: 0.8392 - val_loss: 0.4076\n",
      "Epoch 159/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8351 - loss: 0.3931 - val_accuracy: 0.8392 - val_loss: 0.4066\n",
      "Epoch 160/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.3972 - val_accuracy: 0.8392 - val_loss: 0.4065\n",
      "Epoch 161/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.4292 - val_accuracy: 0.8392 - val_loss: 0.4062\n",
      "Epoch 162/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8111 - loss: 0.4375 - val_accuracy: 0.8392 - val_loss: 0.4057\n",
      "Epoch 163/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8445 - loss: 0.3774 - val_accuracy: 0.8392 - val_loss: 0.4044\n",
      "Epoch 164/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8346 - loss: 0.3914 - val_accuracy: 0.8392 - val_loss: 0.4065\n",
      "Epoch 165/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8276 - loss: 0.4053 - val_accuracy: 0.8392 - val_loss: 0.4067\n",
      "Epoch 166/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7984 - loss: 0.4500 - val_accuracy: 0.8392 - val_loss: 0.4072\n",
      "Epoch 167/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.4296 - val_accuracy: 0.8392 - val_loss: 0.4069\n",
      "Epoch 168/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8352 - loss: 0.4022 - val_accuracy: 0.8392 - val_loss: 0.4067\n",
      "Epoch 169/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8049 - loss: 0.4308 - val_accuracy: 0.8392 - val_loss: 0.4062\n",
      "Epoch 170/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8165 - loss: 0.4258 - val_accuracy: 0.8392 - val_loss: 0.4045\n",
      "Epoch 171/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7958 - loss: 0.4268 - val_accuracy: 0.8392 - val_loss: 0.4070\n",
      "Epoch 172/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7926 - loss: 0.4624 - val_accuracy: 0.8392 - val_loss: 0.4052\n",
      "Epoch 173/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8205 - loss: 0.3960 - val_accuracy: 0.8392 - val_loss: 0.4058\n",
      "Epoch 174/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7965 - loss: 0.4267 - val_accuracy: 0.8392 - val_loss: 0.4058\n",
      "Epoch 175/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8176 - loss: 0.4158 - val_accuracy: 0.8392 - val_loss: 0.4064\n",
      "Epoch 176/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7931 - loss: 0.4506 - val_accuracy: 0.8392 - val_loss: 0.4049\n",
      "Epoch 177/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8323 - loss: 0.3806 - val_accuracy: 0.8392 - val_loss: 0.4062\n",
      "Epoch 178/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7991 - loss: 0.4266 - val_accuracy: 0.8392 - val_loss: 0.4051\n",
      "Epoch 179/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8160 - loss: 0.4345 - val_accuracy: 0.8322 - val_loss: 0.4079\n",
      "Epoch 180/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8192 - loss: 0.4058 - val_accuracy: 0.8462 - val_loss: 0.4038\n",
      "Epoch 181/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8134 - loss: 0.4364 - val_accuracy: 0.8322 - val_loss: 0.4067\n",
      "Epoch 182/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8038 - loss: 0.4322 - val_accuracy: 0.8462 - val_loss: 0.4046\n",
      "Epoch 183/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8157 - loss: 0.4123 - val_accuracy: 0.8392 - val_loss: 0.4056\n",
      "Epoch 184/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8114 - loss: 0.4232 - val_accuracy: 0.8322 - val_loss: 0.4062\n",
      "Epoch 185/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8319 - loss: 0.4105 - val_accuracy: 0.8392 - val_loss: 0.4054\n",
      "Epoch 186/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7940 - loss: 0.4358 - val_accuracy: 0.8322 - val_loss: 0.4064\n",
      "Epoch 187/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8304 - loss: 0.4047 - val_accuracy: 0.8392 - val_loss: 0.4052\n",
      "Epoch 188/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8036 - loss: 0.4279 - val_accuracy: 0.8322 - val_loss: 0.4064\n",
      "Epoch 189/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8252 - loss: 0.4152 - val_accuracy: 0.8322 - val_loss: 0.4058\n",
      "Epoch 190/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8358 - loss: 0.3969 - val_accuracy: 0.8392 - val_loss: 0.4045\n",
      "Epoch 191/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8003 - loss: 0.4338 - val_accuracy: 0.8392 - val_loss: 0.4047\n",
      "Epoch 192/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8153 - loss: 0.4141 - val_accuracy: 0.8392 - val_loss: 0.4050\n",
      "Epoch 193/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8331 - loss: 0.3836 - val_accuracy: 0.8322 - val_loss: 0.4048\n",
      "Epoch 194/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8108 - loss: 0.4093 - val_accuracy: 0.8252 - val_loss: 0.4064\n",
      "Epoch 195/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.3775 - val_accuracy: 0.8322 - val_loss: 0.4057\n",
      "Epoch 196/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8454 - loss: 0.3963 - val_accuracy: 0.8252 - val_loss: 0.4058\n",
      "Epoch 197/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8166 - loss: 0.4363 - val_accuracy: 0.8392 - val_loss: 0.4047\n",
      "Epoch 198/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8316 - loss: 0.3934 - val_accuracy: 0.8392 - val_loss: 0.4029\n",
      "Epoch 199/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7952 - loss: 0.4515 - val_accuracy: 0.8322 - val_loss: 0.4051\n",
      "Epoch 200/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8218 - loss: 0.4120 - val_accuracy: 0.8392 - val_loss: 0.4039\n",
      "Epoch 201/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8220 - loss: 0.4210 - val_accuracy: 0.8322 - val_loss: 0.4040\n",
      "Epoch 202/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7962 - loss: 0.4442 - val_accuracy: 0.8322 - val_loss: 0.4045\n",
      "Epoch 203/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8140 - loss: 0.4394 - val_accuracy: 0.8322 - val_loss: 0.4038\n",
      "Epoch 204/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8269 - loss: 0.4108 - val_accuracy: 0.8322 - val_loss: 0.4030\n",
      "Epoch 205/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8345 - loss: 0.4053 - val_accuracy: 0.8322 - val_loss: 0.4019\n",
      "Epoch 206/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8076 - loss: 0.4164 - val_accuracy: 0.8252 - val_loss: 0.4046\n",
      "Epoch 207/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8065 - loss: 0.4323 - val_accuracy: 0.8322 - val_loss: 0.4035\n",
      "Epoch 208/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8206 - loss: 0.3982 - val_accuracy: 0.8322 - val_loss: 0.4040\n",
      "Epoch 209/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.3926 - val_accuracy: 0.8322 - val_loss: 0.4019\n",
      "Epoch 210/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8239 - loss: 0.4104 - val_accuracy: 0.8322 - val_loss: 0.4041\n",
      "Epoch 211/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8100 - loss: 0.4340 - val_accuracy: 0.8322 - val_loss: 0.4031\n",
      "Epoch 212/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8400 - loss: 0.3900 - val_accuracy: 0.8322 - val_loss: 0.4022\n",
      "Epoch 213/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8055 - loss: 0.4596 - val_accuracy: 0.8322 - val_loss: 0.4033\n",
      "Epoch 214/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8164 - loss: 0.4189 - val_accuracy: 0.8322 - val_loss: 0.4029\n",
      "Epoch 215/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8314 - loss: 0.4033 - val_accuracy: 0.8322 - val_loss: 0.4006\n",
      "Epoch 216/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8278 - loss: 0.4301 - val_accuracy: 0.8322 - val_loss: 0.4020\n",
      "Epoch 217/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8317 - loss: 0.3961 - val_accuracy: 0.8322 - val_loss: 0.4017\n",
      "Epoch 218/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8104 - loss: 0.4236 - val_accuracy: 0.8322 - val_loss: 0.4036\n",
      "Epoch 219/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8404 - loss: 0.3796 - val_accuracy: 0.8322 - val_loss: 0.4015\n",
      "Epoch 220/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8361 - loss: 0.3952 - val_accuracy: 0.8322 - val_loss: 0.4010\n",
      "Epoch 221/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8447 - loss: 0.3937 - val_accuracy: 0.8322 - val_loss: 0.4019\n",
      "Epoch 222/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8339 - loss: 0.3907 - val_accuracy: 0.8322 - val_loss: 0.4017\n",
      "Epoch 223/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8385 - loss: 0.3906 - val_accuracy: 0.8322 - val_loss: 0.4017\n",
      "Epoch 224/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8394 - loss: 0.3739 - val_accuracy: 0.8322 - val_loss: 0.4007\n",
      "Epoch 225/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8412 - loss: 0.4059 - val_accuracy: 0.8322 - val_loss: 0.4024\n",
      "Epoch 226/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8323 - loss: 0.4043 - val_accuracy: 0.8322 - val_loss: 0.4018\n",
      "Epoch 227/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8320 - loss: 0.4029 - val_accuracy: 0.8322 - val_loss: 0.4020\n",
      "Epoch 228/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8566 - loss: 0.3766 - val_accuracy: 0.8322 - val_loss: 0.3998\n",
      "Epoch 229/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8309 - loss: 0.3900 - val_accuracy: 0.8322 - val_loss: 0.3999\n",
      "Epoch 230/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8102 - loss: 0.4301 - val_accuracy: 0.8322 - val_loss: 0.3991\n",
      "Epoch 231/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.4207 - val_accuracy: 0.8322 - val_loss: 0.3994\n",
      "Epoch 232/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8465 - loss: 0.3923 - val_accuracy: 0.8322 - val_loss: 0.4002\n",
      "Epoch 233/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4329 - val_accuracy: 0.8322 - val_loss: 0.4008\n",
      "Epoch 234/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8332 - loss: 0.4209 - val_accuracy: 0.8322 - val_loss: 0.3997\n",
      "Epoch 235/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8499 - loss: 0.3754 - val_accuracy: 0.8322 - val_loss: 0.3985\n",
      "Epoch 236/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8249 - loss: 0.4055 - val_accuracy: 0.8322 - val_loss: 0.3990\n",
      "Epoch 237/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8452 - loss: 0.3733 - val_accuracy: 0.8322 - val_loss: 0.3984\n",
      "Epoch 238/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8226 - loss: 0.4313 - val_accuracy: 0.8322 - val_loss: 0.3993\n",
      "Epoch 239/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8510 - loss: 0.3900 - val_accuracy: 0.8322 - val_loss: 0.3992\n",
      "Epoch 240/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8453 - loss: 0.3851 - val_accuracy: 0.8322 - val_loss: 0.3978\n",
      "Epoch 241/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8508 - loss: 0.3871 - val_accuracy: 0.8322 - val_loss: 0.3997\n",
      "Epoch 242/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8208 - loss: 0.3966 - val_accuracy: 0.8322 - val_loss: 0.3998\n",
      "Epoch 243/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8394 - loss: 0.3901 - val_accuracy: 0.8322 - val_loss: 0.3982\n",
      "Epoch 244/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8556 - loss: 0.3748 - val_accuracy: 0.8322 - val_loss: 0.3977\n",
      "Epoch 245/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8396 - loss: 0.3938 - val_accuracy: 0.8322 - val_loss: 0.3995\n",
      "Epoch 246/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8161 - loss: 0.4113 - val_accuracy: 0.8322 - val_loss: 0.3977\n",
      "Epoch 247/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8454 - loss: 0.3806 - val_accuracy: 0.8322 - val_loss: 0.3979\n",
      "Epoch 248/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8232 - loss: 0.4031 - val_accuracy: 0.8322 - val_loss: 0.3986\n",
      "Epoch 249/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8151 - loss: 0.3976 - val_accuracy: 0.8322 - val_loss: 0.3983\n",
      "Epoch 250/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8431 - loss: 0.3837 - val_accuracy: 0.8322 - val_loss: 0.3981\n",
      "Epoch 251/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8441 - loss: 0.3921 - val_accuracy: 0.8322 - val_loss: 0.3970\n",
      "Epoch 252/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8395 - loss: 0.3938 - val_accuracy: 0.8322 - val_loss: 0.3976\n",
      "Epoch 253/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8358 - loss: 0.3894 - val_accuracy: 0.8322 - val_loss: 0.3970\n",
      "Epoch 254/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8258 - loss: 0.4119 - val_accuracy: 0.8322 - val_loss: 0.3980\n",
      "Epoch 255/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8652 - loss: 0.3494 - val_accuracy: 0.8322 - val_loss: 0.3967\n",
      "Epoch 256/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8345 - loss: 0.3933 - val_accuracy: 0.8322 - val_loss: 0.3984\n",
      "Epoch 257/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8426 - loss: 0.3968 - val_accuracy: 0.8322 - val_loss: 0.3954\n",
      "Epoch 258/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8341 - loss: 0.3808 - val_accuracy: 0.8322 - val_loss: 0.3974\n",
      "Epoch 259/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8396 - loss: 0.3861 - val_accuracy: 0.8322 - val_loss: 0.3977\n",
      "Epoch 260/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8357 - loss: 0.3713 - val_accuracy: 0.8322 - val_loss: 0.3959\n",
      "Epoch 261/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8191 - loss: 0.4125 - val_accuracy: 0.8322 - val_loss: 0.3972\n",
      "Epoch 262/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8197 - loss: 0.4040 - val_accuracy: 0.8322 - val_loss: 0.3966\n",
      "Epoch 263/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.4060 - val_accuracy: 0.8322 - val_loss: 0.3968\n",
      "Epoch 264/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8195 - loss: 0.4070 - val_accuracy: 0.8322 - val_loss: 0.3960\n",
      "Epoch 265/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8378 - loss: 0.3850 - val_accuracy: 0.8322 - val_loss: 0.3951\n",
      "Epoch 266/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8230 - loss: 0.4152 - val_accuracy: 0.8322 - val_loss: 0.3952\n",
      "Epoch 267/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8533 - loss: 0.3702 - val_accuracy: 0.8322 - val_loss: 0.3962\n",
      "Epoch 268/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8357 - loss: 0.3938 - val_accuracy: 0.8322 - val_loss: 0.3966\n",
      "Epoch 269/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8272 - loss: 0.4082 - val_accuracy: 0.8322 - val_loss: 0.3946\n",
      "Epoch 270/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8300 - loss: 0.3889 - val_accuracy: 0.8322 - val_loss: 0.3950\n",
      "Epoch 271/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8295 - loss: 0.3895 - val_accuracy: 0.8322 - val_loss: 0.3972\n",
      "Epoch 272/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8350 - loss: 0.3939 - val_accuracy: 0.8322 - val_loss: 0.3957\n",
      "Epoch 273/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8329 - loss: 0.3867 - val_accuracy: 0.8322 - val_loss: 0.3955\n",
      "Epoch 274/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8367 - loss: 0.3859 - val_accuracy: 0.8322 - val_loss: 0.3954\n",
      "Epoch 275/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8092 - loss: 0.4238 - val_accuracy: 0.8322 - val_loss: 0.3954\n",
      "Epoch 276/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8222 - loss: 0.4097 - val_accuracy: 0.8322 - val_loss: 0.3944\n",
      "Epoch 277/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8335 - loss: 0.3924 - val_accuracy: 0.8322 - val_loss: 0.3944\n",
      "Epoch 278/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8281 - loss: 0.3950 - val_accuracy: 0.8322 - val_loss: 0.3955\n",
      "Epoch 279/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.3706 - val_accuracy: 0.8322 - val_loss: 0.3962\n",
      "Epoch 280/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8359 - loss: 0.3861 - val_accuracy: 0.8322 - val_loss: 0.3952\n",
      "Epoch 281/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.3719 - val_accuracy: 0.8322 - val_loss: 0.3951\n",
      "Epoch 282/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8192 - loss: 0.4158 - val_accuracy: 0.8322 - val_loss: 0.3956\n",
      "Epoch 283/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8248 - loss: 0.3888 - val_accuracy: 0.8322 - val_loss: 0.3953\n",
      "Epoch 284/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.4424 - val_accuracy: 0.8322 - val_loss: 0.3944\n",
      "Epoch 285/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8339 - loss: 0.3962 - val_accuracy: 0.8322 - val_loss: 0.3953\n",
      "Epoch 286/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8037 - loss: 0.4390 - val_accuracy: 0.8322 - val_loss: 0.3959\n",
      "Epoch 287/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8490 - loss: 0.3812 - val_accuracy: 0.8322 - val_loss: 0.3936\n",
      "Epoch 288/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8283 - loss: 0.4004 - val_accuracy: 0.8322 - val_loss: 0.3949\n",
      "Epoch 289/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8363 - loss: 0.3796 - val_accuracy: 0.8252 - val_loss: 0.3967\n",
      "Epoch 290/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8026 - loss: 0.4384 - val_accuracy: 0.8322 - val_loss: 0.3961\n",
      "Epoch 291/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8196 - loss: 0.4327 - val_accuracy: 0.8322 - val_loss: 0.3947\n",
      "Epoch 292/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8325 - loss: 0.3580 - val_accuracy: 0.8322 - val_loss: 0.3941\n",
      "Epoch 293/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.3802 - val_accuracy: 0.8322 - val_loss: 0.3956\n",
      "Epoch 294/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8561 - loss: 0.3723 - val_accuracy: 0.8322 - val_loss: 0.3947\n",
      "Epoch 295/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8364 - loss: 0.3908 - val_accuracy: 0.8252 - val_loss: 0.3965\n",
      "Epoch 296/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8294 - loss: 0.3913 - val_accuracy: 0.8322 - val_loss: 0.3939\n",
      "Epoch 297/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8488 - loss: 0.3662 - val_accuracy: 0.8252 - val_loss: 0.3962\n",
      "Epoch 298/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8239 - loss: 0.4188 - val_accuracy: 0.8252 - val_loss: 0.3957\n",
      "Epoch 299/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8307 - loss: 0.4087 - val_accuracy: 0.8252 - val_loss: 0.3952\n",
      "Epoch 300/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8447 - loss: 0.3930 - val_accuracy: 0.8252 - val_loss: 0.3954\n",
      "Epoch 301/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8211 - loss: 0.3991 - val_accuracy: 0.8252 - val_loss: 0.3961\n",
      "Epoch 302/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8469 - loss: 0.3800 - val_accuracy: 0.8252 - val_loss: 0.3961\n",
      "Epoch 303/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8385 - loss: 0.3853 - val_accuracy: 0.8252 - val_loss: 0.3955\n",
      "Epoch 304/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8414 - loss: 0.3735 - val_accuracy: 0.8322 - val_loss: 0.3944\n",
      "Epoch 305/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8558 - loss: 0.3570 - val_accuracy: 0.8182 - val_loss: 0.3968\n",
      "Epoch 306/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8405 - loss: 0.3856 - val_accuracy: 0.8252 - val_loss: 0.3960\n",
      "Epoch 307/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8410 - loss: 0.3818 - val_accuracy: 0.8322 - val_loss: 0.3952\n",
      "Epoch 308/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 0.4086 - val_accuracy: 0.8252 - val_loss: 0.3966\n",
      "Epoch 309/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8331 - loss: 0.3911 - val_accuracy: 0.8322 - val_loss: 0.3970\n",
      "Epoch 310/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8587 - loss: 0.3566 - val_accuracy: 0.8252 - val_loss: 0.3970\n",
      "Epoch 311/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8449 - loss: 0.3803 - val_accuracy: 0.8252 - val_loss: 0.3968\n",
      "Epoch 312/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8532 - loss: 0.3703 - val_accuracy: 0.8182 - val_loss: 0.3979\n",
      "Epoch 313/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8249 - loss: 0.3999 - val_accuracy: 0.8252 - val_loss: 0.3967\n",
      "Epoch 314/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8349 - loss: 0.4048 - val_accuracy: 0.8322 - val_loss: 0.3965\n",
      "Epoch 315/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8428 - loss: 0.3806 - val_accuracy: 0.8322 - val_loss: 0.3967\n",
      "Epoch 316/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8367 - loss: 0.3963 - val_accuracy: 0.8322 - val_loss: 0.3954\n",
      "Epoch 317/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8428 - loss: 0.3737 - val_accuracy: 0.8322 - val_loss: 0.3970\n",
      "Epoch 318/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8509 - loss: 0.3590 - val_accuracy: 0.8322 - val_loss: 0.3972\n",
      "Epoch 319/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8243 - loss: 0.4243 - val_accuracy: 0.8252 - val_loss: 0.3984\n",
      "Epoch 320/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.4232 - val_accuracy: 0.8322 - val_loss: 0.3983\n",
      "Epoch 321/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8303 - loss: 0.3883 - val_accuracy: 0.8322 - val_loss: 0.3968\n",
      "Epoch 322/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8361 - loss: 0.3924 - val_accuracy: 0.8322 - val_loss: 0.3965\n",
      "Epoch 323/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8478 - loss: 0.3875 - val_accuracy: 0.8322 - val_loss: 0.3964\n",
      "Epoch 324/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8400 - loss: 0.3851 - val_accuracy: 0.8322 - val_loss: 0.3976\n",
      "Epoch 325/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.4176 - val_accuracy: 0.8322 - val_loss: 0.3983\n",
      "Epoch 326/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8124 - loss: 0.4226 - val_accuracy: 0.8252 - val_loss: 0.3990\n",
      "Epoch 327/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7998 - loss: 0.4260 - val_accuracy: 0.8322 - val_loss: 0.3980\n",
      "Epoch 328/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8445 - loss: 0.3718 - val_accuracy: 0.8322 - val_loss: 0.3978\n",
      "Epoch 329/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8128 - loss: 0.4246 - val_accuracy: 0.8322 - val_loss: 0.3975\n",
      "Epoch 330/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8432 - loss: 0.3888 - val_accuracy: 0.8322 - val_loss: 0.3976\n",
      "Epoch 331/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8346 - loss: 0.3896 - val_accuracy: 0.8322 - val_loss: 0.3990\n",
      "Epoch 332/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8305 - loss: 0.3888 - val_accuracy: 0.8252 - val_loss: 0.3986\n",
      "Epoch 333/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8248 - loss: 0.4061 - val_accuracy: 0.8322 - val_loss: 0.3993\n",
      "Epoch 334/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8361 - loss: 0.3758 - val_accuracy: 0.8322 - val_loss: 0.3972\n",
      "Epoch 335/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8391 - loss: 0.3709 - val_accuracy: 0.8252 - val_loss: 0.3988\n",
      "Epoch 336/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8341 - loss: 0.3959 - val_accuracy: 0.8322 - val_loss: 0.3993\n",
      "Epoch 337/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8167 - loss: 0.4051 - val_accuracy: 0.8322 - val_loss: 0.3994\n",
      "Epoch 338/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8171 - loss: 0.4231 - val_accuracy: 0.8322 - val_loss: 0.3996\n",
      "Epoch 339/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8586 - loss: 0.3523 - val_accuracy: 0.8252 - val_loss: 0.3982\n",
      "Epoch 340/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 0.4161 - val_accuracy: 0.8322 - val_loss: 0.3985\n",
      "Epoch 341/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8359 - loss: 0.3772 - val_accuracy: 0.8252 - val_loss: 0.3988\n",
      "Epoch 342/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8473 - loss: 0.3641 - val_accuracy: 0.8252 - val_loss: 0.3985\n",
      "Epoch 343/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8311 - loss: 0.3746 - val_accuracy: 0.8322 - val_loss: 0.4006\n",
      "Epoch 344/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8246 - loss: 0.3906 - val_accuracy: 0.8322 - val_loss: 0.4013\n",
      "Epoch 345/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8185 - loss: 0.3941 - val_accuracy: 0.8322 - val_loss: 0.3986\n",
      "Epoch 346/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8202 - loss: 0.4023 - val_accuracy: 0.8252 - val_loss: 0.4008\n",
      "Epoch 347/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8167 - loss: 0.4157 - val_accuracy: 0.8322 - val_loss: 0.3983\n",
      "Epoch 348/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8456 - loss: 0.3674 - val_accuracy: 0.8252 - val_loss: 0.3998\n",
      "Epoch 349/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8117 - loss: 0.4217 - val_accuracy: 0.8252 - val_loss: 0.4007\n",
      "Epoch 350/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8330 - loss: 0.3966 - val_accuracy: 0.8252 - val_loss: 0.4000\n",
      "Epoch 351/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8475 - loss: 0.3885 - val_accuracy: 0.8252 - val_loss: 0.3989\n",
      "Epoch 352/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8320 - loss: 0.3815 - val_accuracy: 0.8252 - val_loss: 0.3995\n",
      "Epoch 353/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.4152 - val_accuracy: 0.8252 - val_loss: 0.4004\n",
      "Epoch 354/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8372 - loss: 0.3967 - val_accuracy: 0.8252 - val_loss: 0.4015\n",
      "Epoch 355/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8427 - loss: 0.3897 - val_accuracy: 0.8252 - val_loss: 0.3999\n",
      "Epoch 356/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8339 - loss: 0.3821 - val_accuracy: 0.8252 - val_loss: 0.3998\n",
      "Epoch 357/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8260 - loss: 0.4083 - val_accuracy: 0.8252 - val_loss: 0.4003\n",
      "Epoch 358/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8416 - loss: 0.3699 - val_accuracy: 0.8182 - val_loss: 0.4022\n",
      "Epoch 359/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8473 - loss: 0.3792 - val_accuracy: 0.8252 - val_loss: 0.4010\n",
      "Epoch 360/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8395 - loss: 0.3743 - val_accuracy: 0.8252 - val_loss: 0.3993\n",
      "Epoch 361/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8280 - loss: 0.4072 - val_accuracy: 0.8182 - val_loss: 0.4021\n",
      "Epoch 362/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8214 - loss: 0.3936 - val_accuracy: 0.8252 - val_loss: 0.4013\n",
      "Epoch 363/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8333 - loss: 0.3665 - val_accuracy: 0.8322 - val_loss: 0.3992\n",
      "Epoch 364/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8463 - loss: 0.3669 - val_accuracy: 0.8182 - val_loss: 0.4016\n",
      "Epoch 365/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8112 - loss: 0.4229 - val_accuracy: 0.8182 - val_loss: 0.4025\n",
      "Epoch 366/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8457 - loss: 0.3767 - val_accuracy: 0.8182 - val_loss: 0.4006\n",
      "Epoch 367/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8197 - loss: 0.4021 - val_accuracy: 0.8182 - val_loss: 0.4012\n",
      "Epoch 368/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8471 - loss: 0.3777 - val_accuracy: 0.8182 - val_loss: 0.4018\n",
      "Epoch 369/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8283 - loss: 0.3800 - val_accuracy: 0.8182 - val_loss: 0.4017\n",
      "Epoch 370/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8532 - loss: 0.3450 - val_accuracy: 0.8252 - val_loss: 0.3990\n",
      "Epoch 371/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8318 - loss: 0.3935 - val_accuracy: 0.8252 - val_loss: 0.4017\n",
      "Epoch 372/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8300 - loss: 0.3779 - val_accuracy: 0.8182 - val_loss: 0.4017\n",
      "Epoch 373/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8304 - loss: 0.3868 - val_accuracy: 0.8182 - val_loss: 0.4029\n",
      "Epoch 374/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8387 - loss: 0.3804 - val_accuracy: 0.8182 - val_loss: 0.4025\n",
      "Epoch 375/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8507 - loss: 0.3499 - val_accuracy: 0.8182 - val_loss: 0.4034\n",
      "Epoch 376/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8339 - loss: 0.3898 - val_accuracy: 0.8182 - val_loss: 0.4030\n",
      "Epoch 377/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8455 - loss: 0.3598 - val_accuracy: 0.8182 - val_loss: 0.4036\n",
      "Epoch 378/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8295 - loss: 0.3789 - val_accuracy: 0.8182 - val_loss: 0.4046\n",
      "Epoch 379/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8295 - loss: 0.3958 - val_accuracy: 0.8182 - val_loss: 0.4036\n",
      "Epoch 380/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8261 - loss: 0.4037 - val_accuracy: 0.8182 - val_loss: 0.4038\n",
      "Epoch 381/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8346 - loss: 0.3879 - val_accuracy: 0.8252 - val_loss: 0.4051\n",
      "Epoch 382/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8557 - loss: 0.3554 - val_accuracy: 0.8252 - val_loss: 0.4024\n",
      "Epoch 383/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8239 - loss: 0.3865 - val_accuracy: 0.8182 - val_loss: 0.4054\n",
      "Epoch 384/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8508 - loss: 0.3847 - val_accuracy: 0.8182 - val_loss: 0.4059\n",
      "Epoch 385/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8549 - loss: 0.3542 - val_accuracy: 0.8252 - val_loss: 0.4039\n",
      "Epoch 386/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8449 - loss: 0.4002 - val_accuracy: 0.8252 - val_loss: 0.4050\n",
      "Epoch 387/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8228 - loss: 0.3940 - val_accuracy: 0.8252 - val_loss: 0.4055\n",
      "Epoch 388/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8348 - loss: 0.3750 - val_accuracy: 0.8252 - val_loss: 0.4039\n",
      "Epoch 389/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 0.3697 - val_accuracy: 0.8182 - val_loss: 0.4053\n",
      "Epoch 390/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8389 - loss: 0.3760 - val_accuracy: 0.8252 - val_loss: 0.4035\n",
      "Epoch 391/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8536 - loss: 0.3678 - val_accuracy: 0.8252 - val_loss: 0.4044\n",
      "Epoch 392/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8429 - loss: 0.3779 - val_accuracy: 0.8252 - val_loss: 0.4042\n",
      "Epoch 393/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8172 - loss: 0.4033 - val_accuracy: 0.8182 - val_loss: 0.4054\n",
      "Epoch 394/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8378 - loss: 0.3818 - val_accuracy: 0.8252 - val_loss: 0.4050\n",
      "Epoch 395/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8665 - loss: 0.3490 - val_accuracy: 0.8252 - val_loss: 0.4070\n",
      "Epoch 396/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8481 - loss: 0.3761 - val_accuracy: 0.8252 - val_loss: 0.4043\n",
      "Epoch 397/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8454 - loss: 0.3671 - val_accuracy: 0.8182 - val_loss: 0.4050\n",
      "Epoch 398/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8690 - loss: 0.3491 - val_accuracy: 0.8252 - val_loss: 0.4049\n",
      "Epoch 399/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8153 - loss: 0.4271 - val_accuracy: 0.8182 - val_loss: 0.4059\n",
      "Epoch 400/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8396 - loss: 0.3882 - val_accuracy: 0.8252 - val_loss: 0.4041\n",
      "Epoch 401/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8318 - loss: 0.3767 - val_accuracy: 0.8182 - val_loss: 0.4057\n",
      "Epoch 402/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8269 - loss: 0.3873 - val_accuracy: 0.8252 - val_loss: 0.4046\n",
      "Epoch 403/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8464 - loss: 0.3725 - val_accuracy: 0.8252 - val_loss: 0.4043\n",
      "Epoch 404/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8630 - loss: 0.3559 - val_accuracy: 0.8182 - val_loss: 0.4055\n",
      "Epoch 405/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8442 - loss: 0.3789 - val_accuracy: 0.8322 - val_loss: 0.4049\n",
      "Epoch 406/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8261 - loss: 0.3806 - val_accuracy: 0.8252 - val_loss: 0.4044\n",
      "Epoch 407/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8538 - loss: 0.3658 - val_accuracy: 0.8252 - val_loss: 0.4048\n",
      "Epoch 408/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8347 - loss: 0.4067 - val_accuracy: 0.8252 - val_loss: 0.4052\n",
      "Epoch 409/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8479 - loss: 0.3718 - val_accuracy: 0.8392 - val_loss: 0.4033\n",
      "Epoch 410/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8249 - loss: 0.4001 - val_accuracy: 0.8392 - val_loss: 0.4034\n",
      "Epoch 411/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8663 - loss: 0.3426 - val_accuracy: 0.8322 - val_loss: 0.4050\n",
      "Epoch 412/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8332 - loss: 0.3813 - val_accuracy: 0.8252 - val_loss: 0.4052\n",
      "Epoch 413/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8563 - loss: 0.3620 - val_accuracy: 0.8252 - val_loss: 0.4048\n",
      "Epoch 414/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8309 - loss: 0.3818 - val_accuracy: 0.8392 - val_loss: 0.4037\n",
      "Epoch 415/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8439 - loss: 0.3756 - val_accuracy: 0.8252 - val_loss: 0.4048\n",
      "Epoch 416/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8309 - loss: 0.4110 - val_accuracy: 0.8322 - val_loss: 0.4050\n",
      "Epoch 417/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8685 - loss: 0.3469 - val_accuracy: 0.8392 - val_loss: 0.4030\n",
      "Epoch 418/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8681 - loss: 0.3246 - val_accuracy: 0.8252 - val_loss: 0.4055\n",
      "Epoch 419/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8355 - loss: 0.3757 - val_accuracy: 0.8322 - val_loss: 0.4058\n",
      "Epoch 420/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8391 - loss: 0.4022 - val_accuracy: 0.8392 - val_loss: 0.4038\n",
      "Epoch 421/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8396 - loss: 0.3952 - val_accuracy: 0.8322 - val_loss: 0.4053\n",
      "Epoch 422/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8449 - loss: 0.3766 - val_accuracy: 0.8322 - val_loss: 0.4059\n",
      "Epoch 423/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8312 - loss: 0.3881 - val_accuracy: 0.8392 - val_loss: 0.4040\n",
      "Epoch 424/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8608 - loss: 0.3561 - val_accuracy: 0.8392 - val_loss: 0.4049\n",
      "Epoch 425/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8246 - loss: 0.3838 - val_accuracy: 0.8322 - val_loss: 0.4051\n",
      "Epoch 426/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.4099 - val_accuracy: 0.8322 - val_loss: 0.4049\n",
      "Epoch 427/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8663 - loss: 0.3460 - val_accuracy: 0.8392 - val_loss: 0.4045\n",
      "Epoch 428/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8635 - loss: 0.3415 - val_accuracy: 0.8392 - val_loss: 0.4046\n",
      "Epoch 429/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8395 - loss: 0.3939 - val_accuracy: 0.8322 - val_loss: 0.4070\n",
      "Epoch 430/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8463 - loss: 0.3751 - val_accuracy: 0.8392 - val_loss: 0.4043\n",
      "Epoch 431/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8304 - loss: 0.3749 - val_accuracy: 0.8462 - val_loss: 0.4048\n",
      "Epoch 432/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8683 - loss: 0.3477 - val_accuracy: 0.8392 - val_loss: 0.4052\n",
      "Epoch 433/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8581 - loss: 0.3594 - val_accuracy: 0.8322 - val_loss: 0.4058\n",
      "Epoch 434/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8572 - loss: 0.3535 - val_accuracy: 0.8322 - val_loss: 0.4072\n",
      "Epoch 435/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8419 - loss: 0.3720 - val_accuracy: 0.8322 - val_loss: 0.4064\n",
      "Epoch 436/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.3755 - val_accuracy: 0.8322 - val_loss: 0.4067\n",
      "Epoch 437/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8710 - loss: 0.3397 - val_accuracy: 0.8392 - val_loss: 0.4056\n",
      "Epoch 438/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8567 - loss: 0.3431 - val_accuracy: 0.8392 - val_loss: 0.4061\n",
      "Epoch 439/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8300 - loss: 0.3966 - val_accuracy: 0.8322 - val_loss: 0.4066\n",
      "Epoch 440/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8533 - loss: 0.3541 - val_accuracy: 0.8392 - val_loss: 0.4060\n",
      "Epoch 441/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8235 - loss: 0.4207 - val_accuracy: 0.8322 - val_loss: 0.4078\n",
      "Epoch 442/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8352 - loss: 0.3807 - val_accuracy: 0.8322 - val_loss: 0.4068\n",
      "Epoch 443/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8620 - loss: 0.3502 - val_accuracy: 0.8392 - val_loss: 0.4060\n",
      "Epoch 444/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8628 - loss: 0.3507 - val_accuracy: 0.8322 - val_loss: 0.4075\n",
      "Epoch 445/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8476 - loss: 0.3521 - val_accuracy: 0.8322 - val_loss: 0.4076\n",
      "Epoch 446/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8399 - loss: 0.3810 - val_accuracy: 0.8322 - val_loss: 0.4063\n",
      "Epoch 447/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8525 - loss: 0.3393 - val_accuracy: 0.8392 - val_loss: 0.4067\n",
      "Epoch 448/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8382 - loss: 0.3630 - val_accuracy: 0.8322 - val_loss: 0.4077\n",
      "Epoch 449/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8440 - loss: 0.3715 - val_accuracy: 0.8392 - val_loss: 0.4063\n",
      "Epoch 450/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 0.3699 - val_accuracy: 0.8322 - val_loss: 0.4085\n",
      "Epoch 451/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8508 - loss: 0.3672 - val_accuracy: 0.8322 - val_loss: 0.4074\n",
      "Epoch 452/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8616 - loss: 0.3390 - val_accuracy: 0.8322 - val_loss: 0.4080\n",
      "Epoch 453/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.3739 - val_accuracy: 0.8322 - val_loss: 0.4080\n",
      "Epoch 454/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8650 - loss: 0.3573 - val_accuracy: 0.8392 - val_loss: 0.4066\n",
      "Epoch 455/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8441 - loss: 0.3852 - val_accuracy: 0.8322 - val_loss: 0.4073\n",
      "Epoch 456/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8492 - loss: 0.3831 - val_accuracy: 0.8322 - val_loss: 0.4071\n",
      "Epoch 457/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8531 - loss: 0.3591 - val_accuracy: 0.8322 - val_loss: 0.4075\n",
      "Epoch 458/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8523 - loss: 0.3657 - val_accuracy: 0.8322 - val_loss: 0.4080\n",
      "Epoch 459/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8471 - loss: 0.3780 - val_accuracy: 0.8392 - val_loss: 0.4066\n",
      "Epoch 460/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8310 - loss: 0.3586 - val_accuracy: 0.8322 - val_loss: 0.4077\n",
      "Epoch 461/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8494 - loss: 0.3686 - val_accuracy: 0.8322 - val_loss: 0.4102\n",
      "Epoch 462/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8637 - loss: 0.3496 - val_accuracy: 0.8392 - val_loss: 0.4072\n",
      "Epoch 463/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8574 - loss: 0.3550 - val_accuracy: 0.8322 - val_loss: 0.4087\n",
      "Epoch 464/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8630 - loss: 0.3520 - val_accuracy: 0.8322 - val_loss: 0.4091\n",
      "Epoch 465/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8534 - loss: 0.3716 - val_accuracy: 0.8322 - val_loss: 0.4083\n",
      "Epoch 466/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8579 - loss: 0.3652 - val_accuracy: 0.8322 - val_loss: 0.4080\n",
      "Epoch 467/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8410 - loss: 0.3819 - val_accuracy: 0.8322 - val_loss: 0.4085\n",
      "Epoch 468/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8689 - loss: 0.3521 - val_accuracy: 0.8322 - val_loss: 0.4077\n",
      "Epoch 469/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8472 - loss: 0.3764 - val_accuracy: 0.8322 - val_loss: 0.4094\n",
      "Epoch 470/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8659 - loss: 0.3637 - val_accuracy: 0.8322 - val_loss: 0.4092\n",
      "Epoch 471/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8507 - loss: 0.3919 - val_accuracy: 0.8322 - val_loss: 0.4092\n",
      "Epoch 472/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8404 - loss: 0.3841 - val_accuracy: 0.8322 - val_loss: 0.4083\n",
      "Epoch 473/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8342 - loss: 0.3707 - val_accuracy: 0.8252 - val_loss: 0.4074\n",
      "Epoch 474/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8468 - loss: 0.3646 - val_accuracy: 0.8322 - val_loss: 0.4083\n",
      "Epoch 475/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8314 - loss: 0.4046 - val_accuracy: 0.8322 - val_loss: 0.4101\n",
      "Epoch 476/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8466 - loss: 0.3775 - val_accuracy: 0.8392 - val_loss: 0.4079\n",
      "Epoch 477/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8278 - loss: 0.3725 - val_accuracy: 0.8252 - val_loss: 0.4082\n",
      "Epoch 478/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8307 - loss: 0.3951 - val_accuracy: 0.8252 - val_loss: 0.4076\n",
      "Epoch 479/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8621 - loss: 0.3445 - val_accuracy: 0.8322 - val_loss: 0.4093\n",
      "Epoch 480/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8494 - loss: 0.3868 - val_accuracy: 0.8322 - val_loss: 0.4084\n",
      "Epoch 481/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8563 - loss: 0.3691 - val_accuracy: 0.8322 - val_loss: 0.4101\n",
      "Epoch 482/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8505 - loss: 0.3683 - val_accuracy: 0.8252 - val_loss: 0.4095\n",
      "Epoch 483/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8249 - loss: 0.3959 - val_accuracy: 0.8322 - val_loss: 0.4100\n",
      "Epoch 484/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8497 - loss: 0.3704 - val_accuracy: 0.8322 - val_loss: 0.4103\n",
      "Epoch 485/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.3572 - val_accuracy: 0.8322 - val_loss: 0.4089\n",
      "Epoch 486/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8545 - loss: 0.3463 - val_accuracy: 0.8322 - val_loss: 0.4103\n",
      "Epoch 487/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8516 - loss: 0.3572 - val_accuracy: 0.8322 - val_loss: 0.4101\n",
      "Epoch 488/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8514 - loss: 0.3727 - val_accuracy: 0.8322 - val_loss: 0.4091\n",
      "Epoch 489/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8449 - loss: 0.3808 - val_accuracy: 0.8322 - val_loss: 0.4100\n",
      "Epoch 490/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8570 - loss: 0.3525 - val_accuracy: 0.8322 - val_loss: 0.4101\n",
      "Epoch 491/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8453 - loss: 0.3829 - val_accuracy: 0.8322 - val_loss: 0.4088\n",
      "Epoch 492/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8592 - loss: 0.3527 - val_accuracy: 0.8322 - val_loss: 0.4099\n",
      "Epoch 493/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8500 - loss: 0.3542 - val_accuracy: 0.8322 - val_loss: 0.4093\n",
      "Epoch 494/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8506 - loss: 0.3517 - val_accuracy: 0.8252 - val_loss: 0.4088\n",
      "Epoch 495/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8457 - loss: 0.3816 - val_accuracy: 0.8322 - val_loss: 0.4092\n",
      "Epoch 496/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8564 - loss: 0.3639 - val_accuracy: 0.8322 - val_loss: 0.4108\n",
      "Epoch 497/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8537 - loss: 0.3761 - val_accuracy: 0.8322 - val_loss: 0.4109\n",
      "Epoch 498/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8497 - loss: 0.3710 - val_accuracy: 0.8322 - val_loss: 0.4092\n",
      "Epoch 499/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8663 - loss: 0.3578 - val_accuracy: 0.8322 - val_loss: 0.4102\n",
      "Epoch 500/500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8319 - loss: 0.4102 - val_accuracy: 0.8252 - val_loss: 0.4097\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8281 - loss: 0.4245 \n"
     ]
    }
   ],
   "source": [
    "# Implementation of the assignment\n",
    "\n",
    "# TODO: Compile the model\n",
    "# TODO: Train the neural network with n epoch rounds\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "          epochs=500,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)\n",
    "\n",
    "# TODO: Compare the obtained learning results with the test data\n",
    "results = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a01904af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:33:40.168260Z",
     "start_time": "2024-12-12T14:33:40.155295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.4164809923442105 Test Accuracy:83.24022346368714%\n"
     ]
    }
   ],
   "source": [
    "# Answers to the assignment.\n",
    "# Note! Do not edit this cell, just run it after you complete the assignment. Set the result of the model.evaluate() function in the results variable.\n",
    "\n",
    "# TODO: Be sure to set the model.compile() function to be tracked as metrics=['accuracy'] to define the accuracy of the neural network predictions.\n",
    "print(f\"Test Loss:{results[0]} Test Accuracy:{results[1] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9b09c",
   "metadata": {},
   "source": [
    "About the modeling results:\n",
    "* Test Accuracy: approx. 80% or greater is already pretty good\n",
    "* You can try to get better results for improving your modeling skills\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
